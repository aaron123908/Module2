{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMRMLhMgFVCM5+HyR1uwgti",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aaron123908/Module2/blob/main/Coding_Exercise_ML_Basics.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "fOJLHeIZtgYZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "53a5098c-a96b-442b-b843-70a44a74f1b4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model R² Score: 0.970\n",
            "Mean Absolute Error: $33,169.61\n",
            "\n",
            "Predicted price for a 2000 sq ft house in Downtown: $505,454.26\n",
            "\n",
            "Model Coefficients (Impact on Price):\n",
            "location_Midtown: -138,810.16\n",
            "location_Rural: -288,862.39\n",
            "location_Suburb: -216,614.52\n",
            "square_footage: 176,617.96\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.metrics import mean_absolute_error, r2_score\n",
        "\n",
        "np.random.seed(42)\n",
        "n_samples = 200\n",
        "\n",
        "data = {\n",
        "    'square_footage': np.random.randint(800, 4500, n_samples),\n",
        "    'location': np.random.choice(['Downtown', 'Suburb', 'Rural', 'Midtown'], n_samples),\n",
        "}\n",
        "\n",
        "location_multipliers = {'Downtown': 1.5, 'Midtown': 1.2, 'Suburb': 1.0, 'Rural': 0.8}\n",
        "base_price_per_sqft = 150\n",
        "noise = np.random.normal(0, 25000, n_samples) # Adding random variance\n",
        "\n",
        "df = pd.DataFrame(data)\n",
        "df['price'] = (df['square_footage'] * base_price_per_sqft * df['location'].map(location_multipliers) + noise)\n",
        "\n",
        "X = df[['square_footage', 'location']]\n",
        "y = df['price']\n",
        "\n",
        "preprocessor = ColumnTransformer(\n",
        "    transformers=[\n",
        "        ('cat', OneHotEncoder(drop='first', sparse_output=False), ['location']),\n",
        "        ('num', StandardScaler(), ['square_footage'])\n",
        "    ])\n",
        "\n",
        "model = Pipeline(steps=[\n",
        "    ('preprocessor', preprocessor),\n",
        "    ('regressor', LinearRegression())\n",
        "])\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "y_pred = model.predict(X_test)\n",
        "print(f\"Model R² Score: {r2_score(y_test, y_pred):.3f}\")\n",
        "print(f\"Mean Absolute Error: ${mean_absolute_error(y_test, y_pred):,.2f}\")\n",
        "\n",
        "new_house = pd.DataFrame({'square_footage': [2000], 'location': ['Downtown']})\n",
        "predicted_price = model.predict(new_house)\n",
        "print(f\"\\nPredicted price for a 2000 sq ft house in Downtown: ${predicted_price[0]:,.2f}\")\n",
        "\n",
        "cat_features = model.named_steps['preprocessor'].named_transformers_['cat'].get_feature_names_out(['location']).tolist()\n",
        "feature_names = cat_features + ['square_footage']\n",
        "coefficients = model.named_steps['regressor'].coef_\n",
        "\n",
        "print(\"\\nModel Coefficients (Impact on Price):\")\n",
        "for feature, coef in zip(feature_names, coefficients):\n",
        "    print(f\"{feature}: {coef:,.2f}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "\n",
        "np.random.seed(42)\n",
        "n_samples = 500\n",
        "\n",
        "data = {\n",
        "    'age': np.random.randint(18, 80, n_samples),\n",
        "    'monthly_usage_hours': np.random.uniform(5, 100, n_samples),\n",
        "    'purchase_amount': np.random.uniform(20, 500, n_samples),\n",
        "    'customer_service_calls': np.random.randint(0, 10, n_samples),\n",
        "    'region': np.random.choice(['North', 'South', 'West', 'East'], n_samples)\n",
        "}\n",
        "\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "logit = (0.02 * df['age'] - 0.05 * df['monthly_usage_hours'] +\n",
        "         0.4 * df['customer_service_calls'] - 2.0)\n",
        "prob = 1 / (1 + np.exp(-logit))\n",
        "df['churn'] = (prob > np.random.rand(n_samples)).astype(int)\n",
        "\n",
        "X = df.drop('churn', axis=1)\n",
        "y = df['churn']\n",
        "\n",
        "preprocessor = ColumnTransformer(\n",
        "    transformers=[\n",
        "        ('num', StandardScaler(), ['age', 'monthly_usage_hours', 'purchase_amount', 'customer_service_calls']),\n",
        "        ('cat', OneHotEncoder(drop='first', sparse_output=False), ['region'])\n",
        "    ])\n",
        "\n",
        "model = Pipeline(steps=[\n",
        "    ('preprocessor', preprocessor),\n",
        "    ('classifier', LogisticRegression(random_state=42, class_weight='balanced'))\n",
        "])\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "y_pred = model.predict(X_test)\n",
        "print(\"Model Performance Report:\")\n",
        "print(classification_report(y_test, y_pred))\n",
        "\n",
        "new_customer = pd.DataFrame({\n",
        "    'age': [35],\n",
        "    'monthly_usage_hours': [20],\n",
        "    'purchase_amount': [150],\n",
        "    'customer_service_calls': [5],\n",
        "    'region': ['West']\n",
        "})\n",
        "\n",
        "prob = model.predict_proba(new_customer)[0][1]\n",
        "print(f\"Churn Probability for new customer: {prob:.2%}\")\n",
        "\n",
        "cat_features = model.named_steps['preprocessor'].named_transformers_['cat'].get_feature_names_out(['region']).tolist()\n",
        "num_features = ['age', 'monthly_usage_hours', 'purchase_amount', 'customer_service_calls']\n",
        "feature_names = num_features + cat_features\n",
        "coefficients = model.named_steps['classifier'].coef_[0]\n",
        "\n",
        "print(\"\\nFeature Impact (Coefficients):\")\n",
        "for name, coef in zip(feature_names, coefficients):\n",
        "    print(f\"{name:>25}: {coef:.3f}\")"
      ],
      "metadata": {
        "id": "4dUF942RNboX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import silhouette_score\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "np.random.seed(42)\n",
        "n_samples = 300\n",
        "\n",
        "c1 = {\n",
        "    'annual_spending': np.random.normal(1500, 200, 100),\n",
        "    'purchase_frequency': np.random.normal(20, 3, 100),\n",
        "    'age': np.random.normal(25, 5, 100)\n",
        "}\n",
        "\n",
        "c2 = {\n",
        "    'annual_spending': np.random.normal(800, 150, 100),\n",
        "    'purchase_frequency': np.random.normal(8, 2, 100),\n",
        "    'age': np.random.normal(55, 8, 100)\n",
        "}\n",
        "\n",
        "c3 = {\n",
        "    'annual_spending': np.random.normal(300, 100, 100),\n",
        "    'purchase_frequency': np.random.normal(4, 1.5, 100),\n",
        "    'age': np.random.normal(35, 10, 100)\n",
        "}\n",
        "\n",
        "df = pd.concat([pd.DataFrame(c1), pd.DataFrame(c2), pd.DataFrame(c3)]).sample(frac=1).reset_index(drop=True)\n",
        "df['region'] = np.random.choice(['North', 'South', 'West', 'East'], n_samples)\n",
        "\n",
        "features = ['annual_spending', 'purchase_frequency', 'age']\n",
        "X = df[features]\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "inertia = []\n",
        "K_range = range(1, 11)\n",
        "for k in K_range:\n",
        "    km = KMeans(n_clusters=k, random_state=42, n_init=10)\n",
        "    km.fit(X_scaled)\n",
        "    inertia.append(km.inertia_)\n",
        "\n",
        "optimal_k = 3\n",
        "kmeans = KMeans(n_clusters=optimal_k, random_state=42, n_init=10)\n",
        "df['cluster'] = kmeans.fit_predict(X_scaled)\n",
        "\n",
        "sil_score = silhouette_score(X_scaled, df['cluster'])\n",
        "print(f\"Silhouette Score for K=3: {sil_score:.3f}\")\n",
        "\n",
        "cluster_summary = df.groupby('cluster')[features].mean().round(2)\n",
        "print(\"\\nCluster Characteristics (Averages):\")\n",
        "print(cluster_summary)\n",
        "\n",
        "print(\"\\n--- Strategic Recommendations ---\")\n",
        "for cluster in range(optimal_k):\n",
        "    avg_spend = cluster_summary.loc[cluster, 'annual_spending']\n",
        "    avg_freq = cluster_summary.loc[cluster, 'purchase_frequency']\n",
        "    avg_age = cluster_summary.loc[cluster, 'age']\n",
        "\n",
        "    strategy = f\"Cluster {cluster} (Avg Age {avg_age}): \"\n",
        "    if avg_spend > 1200:\n",
        "        strategy += \"VIP Segment. Focus on premium retention and early access.\"\n",
        "    elif avg_freq > 15:\n",
        "        strategy += \"High Engagement. Offer subscription models to lock in value.\"\n",
        "    elif avg_spend < 500:\n",
        "        strategy += \"Price Sensitive. Use discount-driven re-engagement.\"\n",
        "    else:\n",
        "        strategy += \"Steady Customers. Standard marketing mix.\"\n",
        "    print(strategy)"
      ],
      "metadata": {
        "id": "l8-z2R5xNrwM"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}